{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callisto Test Generation for MNIST-Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "* Python 3\n",
    "* Keras\n",
    "* Tensorflow\n",
    "* Random\n",
    "* Pickle\n",
    "* Math\n",
    "* Matplotlib\n",
    "* OpenCV\n",
    "* h5py\n",
    "* numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model\n",
    "import _pickle as pickle\n",
    "import copy\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please download the pre-trained MNIST model [here](https://drive.google.com/file/d/1bT3ksg_C61kdDtqTDB0-c-5DqYS1D__1/view?usp=sharing) and save it in the \"models\" folder under MNIST-Digit if you download this file independently. If you have downloaded it as part of the GitHub repo, it should be downloaded automatically\n",
    "\n",
    "### MD5 checksum = 9e642043e426595909f3227d1d27646e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_file = \"../models/MNIST.h5py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please change 'MINI_DATASET_TEST' to False if you want to run the full MNIST dataset. Once it is set to true, the test generation framework will only run for a subset images in the interest of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_DATASET_TEST = True\n",
    "MINI_DATASET_N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the training and testing data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train= x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "#Converting the labels to a categorical form\n",
    "y_train=to_categorical(y_train, num_classes=10)\n",
    "y_test=to_categorical(y_test, num_classes=10)\n",
    "\n",
    "if MINI_DATASET_TEST:\n",
    "    x_train = x_train[:MINI_DATASET_N]\n",
    "    x_test = x_test[:MINI_DATASET_N]\n",
    "    y_train = y_train[:MINI_DATASET_N]\n",
    "    y_test = y_test[:MINI_DATASET_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1208 15:14:00.904906 4611214656 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W1208 15:14:00.925935 4611214656 module_wrapper.py:139] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model architechture\n",
    "model1=Sequential()\n",
    "model1.add(Conv2D(8, kernel_size=(3, 3), strides=(1, 1),padding=\"same\",\n",
    "                 kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform',\n",
    "                 activation='relu',input_shape=[28,28,1]))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"valid\"))\n",
    "model1.add(Conv2D(16,kernel_size=(3,3),strides=(1,1),padding=\"same\",\n",
    "                kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform',\n",
    "                activation=\"relu\"))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"valid\"))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(100,activation=\"relu\",kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros'))\n",
    "model1.add(Dense(10,activation=\"softmax\",kernel_initializer='random_uniform',\n",
    "                bias_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights(model1_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1208 15:14:01.303211 4611214656 module_wrapper.py:139] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 138us/step\n",
      "Test accuracy: 0.9829999804496765\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model1.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model1.layers]\n",
    "\n",
    "activation_model = Model(inputs=model1.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all_train_acts.pickle contains all the activations of the training data. This is necesscary for Callisto to calculate the shannon indices of the image input. Please download the file [here](https://drive.google.com/file/d/1xyoIpkv-L0SxMyxGnkSZzBd2JkiqTVJi/view?usp=sharing). The file should be saved in the \"saved_pickles\" folder under MNIST-Digit if you download this file independently. If you have downloaded it as part of the GitHub repo, it should be downloaded automatically\n",
    "\n",
    "### MD5 checksum = 9a7463549e6301c694759436d3c8010b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved_pickles/all_train_acts.pickle', 'rb') as handle: \n",
    "     all_acts = pickle.load(handle)\n",
    "        \n",
    "if MINI_DATASET_TEST:\n",
    "    all_acts = all_acts[:MINI_DATASET_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the Shannon index for all the inputs\n",
    "\n",
    "def shannon(arrs):\n",
    "    shannons = []\n",
    "    for arr in arrs:\n",
    "        sum = 0\n",
    "        for i in arr:\n",
    "            sum += (i*np.log(i))\n",
    "        shannons.append(sum * -1.0)\n",
    "    return shannons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shannons = shannon(all_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_shannon_true: 823\n"
     ]
    }
   ],
   "source": [
    "low_shannon_true = []\n",
    "for i in range(len(all_shannons)):\n",
    "    if all_shannons[i] < 0.001 and np.argmax(all_acts[i]) == np.argmax(y_train[i]) : \n",
    "        low_shannon_true.append(i)\n",
    "        \n",
    "print(\"low_shannon_true:\", len(low_shannon_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols = (28, 28)\n",
    "M = np.float32([[1,0,2],[0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Original Image\")\n",
    "img = x_train[0]\n",
    "label = y_train[0]\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panning Transformation in openCV\n",
    "rows,cols = (28, 28)\n",
    "M = np.float32([[1,0,2],[0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Panning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Transformation: Panning\")\n",
    "rows,cols = (28, 28)\n",
    "M = np.float32([[1,0,2],[0,1,2]])\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "plt.imshow(dst, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Panning\n",
      "Shannon Treshold : < 0.001\n",
      "Number of inputs:  823\n",
      "Error Rate:  0.2235722964763062\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Panning\")\n",
    "cols,rows = 28, 28\n",
    "count_made_false_low_shannon_true = 0\n",
    "for i in low_shannon_true:\n",
    "    img = x_train[i]\n",
    "    label = y_train[i]\n",
    "    img = (np.expand_dims(img,0))\n",
    "    img_pred = activation_model.predict(img)[6][0]\n",
    "    \n",
    "    dst = cv2.warpAffine(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "    dst = (np.expand_dims(dst,0))\n",
    "    dst_pred = activation_model.predict(dst)[6][0]\n",
    "    \n",
    "    if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "        count_made_false_low_shannon_true += 1\n",
    "\n",
    "\n",
    "print(\"Shannon Treshold : < 0.001\")        \n",
    "print(\"Number of inputs: \", len(low_shannon_true))        \n",
    "print(\"Error Rate: \", (count_made_false_low_shannon_true*1.0)/len(low_shannon_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Panning\n",
      "Shannon Treshold : > 0.01\n",
      "Number of inputs:  87\n",
      "Error Rates : 0.4827586206896552\n",
      "\n",
      "Shannon Treshold : > 0.025\n",
      "Number of inputs:  59\n",
      "Error Rates : 0.5423728813559322\n",
      "\n",
      "Shannon Treshold : > 0.05\n",
      "Number of inputs:  43\n",
      "Error Rates : 0.627906976744186\n",
      "\n",
      "Shannon Treshold : > 0.1\n",
      "Number of inputs:  26\n",
      "Error Rates : 0.6923076923076923\n",
      "\n",
      "Shannon Treshold : > 0.2\n",
      "Number of inputs:  17\n",
      "Error Rates : 0.7058823529411765\n",
      "\n",
      "Shannon Treshold : > 0.3\n",
      "Number of inputs:  12\n",
      "Error Rates : 0.8333333333333334\n",
      "\n",
      "Shannon Treshold : > 0.4\n",
      "Number of inputs:  10\n",
      "Error Rates : 0.8\n",
      "\n",
      "Shannon Treshold : > 0.5\n",
      "Number of inputs:  8\n",
      "Error Rates : 0.75\n",
      "\n",
      "Shannon Treshold : > 0.6\n",
      "Number of inputs:  5\n",
      "Error Rates : 0.6\n",
      "\n",
      "Shannon Treshold : > 0.7\n",
      "Number of inputs:  3\n",
      "Error Rates : 0.3333333333333333\n",
      "\n",
      "Shannon Treshold : > 0.8\n",
      "Number of inputs:  2\n",
      "Error Rates : 0.5\n",
      "\n",
      "Shannon Treshold : > 0.9\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  0.9\n",
      "\n",
      "Shannon Treshold : > 1.0\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Panning\")\n",
    "thresholds = [0.01, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    high_shannon_true = []\n",
    "    for i, shannon_index in enumerate(all_shannons):\n",
    "        if shannon_index > threshold and (np.argmax(all_acts[i]) == np.argmax(y_train[i])) : \n",
    "            high_shannon_true.append(i)\n",
    "\n",
    "    print(\"Shannon Treshold : >\", threshold)\n",
    "    print(\"Number of inputs: \", len(high_shannon_true))\n",
    "\n",
    "    count_made_false_high_shannon_true = 0\n",
    "    \n",
    "    if len(high_shannon_true) > 0:\n",
    "        for i in high_shannon_true:\n",
    "            img = x_train[i]\n",
    "            label = y_train[i]\n",
    "            img = (np.expand_dims(img,0))\n",
    "            img_pred = activation_model.predict(img)[6][0]\n",
    "\n",
    "            dst = cv2.warpAffine(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "            dst = (np.expand_dims(dst,0))\n",
    "            dst_pred = activation_model.predict(dst)[6][0]\n",
    "            if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "                count_made_false_high_shannon_true += 1\n",
    "\n",
    "        print(\"Error Rates :\", (count_made_false_high_shannon_true*1.0)/len(high_shannon_true))\n",
    "        \n",
    "    else:\n",
    "        print(\"No inputs with shannon index more than \", threshold)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: 2D rotation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Transformation: 2D rotation\")\n",
    "rows,cols = (28, 28)\n",
    "M = cv2.getRotationMatrix2D((cols/2,rows/2),30,1)\n",
    "img = x_train[0]\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "plt.imshow(dst, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Rotation\n",
      "Shannon Treshold : < 0.001\n",
      "Number of inputs:  823\n",
      "Error Rate:  0.09477521263669501\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Rotation\")\n",
    "cols,rows = 28, 28\n",
    "count_made_false_low_shannon_true = 0\n",
    "for i in low_shannon_true:\n",
    "    img = x_train[i]\n",
    "    label = y_train[i]\n",
    "    img = (np.expand_dims(img,0))\n",
    "    img_pred = activation_model.predict(img)[6][0]\n",
    "    \n",
    "    dst = cv2.warpAffine(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "    dst = (np.expand_dims(dst,0))\n",
    "    dst_pred = activation_model.predict(dst)[6][0]\n",
    "    \n",
    "    if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "        count_made_false_low_shannon_true += 1\n",
    "\n",
    "\n",
    "print(\"Shannon Treshold : < 0.001\")        \n",
    "print(\"Number of inputs: \", len(low_shannon_true))        \n",
    "print(\"Error Rate: \", (count_made_false_low_shannon_true*1.0)/len(low_shannon_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Rotation\n",
      "Shannon Treshold : > 0.01\n",
      "Number of inputs:  87\n",
      "Error Rates : 0.4367816091954023\n",
      "\n",
      "Shannon Treshold : > 0.025\n",
      "Number of inputs:  59\n",
      "Error Rates : 0.4406779661016949\n",
      "\n",
      "Shannon Treshold : > 0.05\n",
      "Number of inputs:  43\n",
      "Error Rates : 0.46511627906976744\n",
      "\n",
      "Shannon Treshold : > 0.1\n",
      "Number of inputs:  26\n",
      "Error Rates : 0.5\n",
      "\n",
      "Shannon Treshold : > 0.2\n",
      "Number of inputs:  17\n",
      "Error Rates : 0.47058823529411764\n",
      "\n",
      "Shannon Treshold : > 0.3\n",
      "Number of inputs:  12\n",
      "Error Rates : 0.3333333333333333\n",
      "\n",
      "Shannon Treshold : > 0.4\n",
      "Number of inputs:  10\n",
      "Error Rates : 0.4\n",
      "\n",
      "Shannon Treshold : > 0.5\n",
      "Number of inputs:  8\n",
      "Error Rates : 0.5\n",
      "\n",
      "Shannon Treshold : > 0.6\n",
      "Number of inputs:  5\n",
      "Error Rates : 0.4\n",
      "\n",
      "Shannon Treshold : > 0.7\n",
      "Number of inputs:  3\n",
      "Error Rates : 0.6666666666666666\n",
      "\n",
      "Shannon Treshold : > 0.8\n",
      "Number of inputs:  2\n",
      "Error Rates : 1.0\n",
      "\n",
      "Shannon Treshold : > 0.9\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  0.9\n",
      "\n",
      "Shannon Treshold : > 1.0\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Rotation\")\n",
    "thresholds = [0.01, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    high_shannon_true = []\n",
    "    for i, shannon_index in enumerate(all_shannons):\n",
    "        if shannon_index > threshold and (np.argmax(all_acts[i]) == np.argmax(y_train[i])) : \n",
    "            high_shannon_true.append(i)\n",
    "\n",
    "    print(\"Shannon Treshold : >\", threshold)\n",
    "    print(\"Number of inputs: \", len(high_shannon_true))\n",
    "\n",
    "    count_made_false_high_shannon_true = 0\n",
    "    \n",
    "    if len(high_shannon_true) > 0:\n",
    "        for i in high_shannon_true:\n",
    "            img = x_train[i]\n",
    "            label = y_train[i]\n",
    "            img = (np.expand_dims(img,0))\n",
    "            img_pred = activation_model.predict(img)[6][0]\n",
    "\n",
    "            dst = cv2.warpAffine(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "            dst = (np.expand_dims(dst,0))\n",
    "            dst_pred = activation_model.predict(dst)[6][0]\n",
    "            if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "                count_made_false_high_shannon_true += 1\n",
    "\n",
    "        print(\"Error Rates :\", (count_made_false_high_shannon_true*1.0)/len(high_shannon_true))\n",
    "        \n",
    "    else:\n",
    "        print(\"No inputs with shannon index more than \", threshold)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Affine\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Transformation: Affine\")\n",
    "rows,cols = (28, 28)\n",
    "pts1 = np.float32([[5,5],[24,5],[5,24]])\n",
    "pts2 = np.float32([[1,10],[20,5],[10,25]])\n",
    "M = cv2.getAffineTransform(pts1,pts2)\n",
    "img = x_train[0]\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "plt.imshow(dst, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Affine\n",
      "Shannon Treshold : < 0.001\n",
      "Number of inputs:  823\n",
      "Error Rate:  0.06439854191980558\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Affine\")\n",
    "cols,rows = 28, 28\n",
    "count_made_false_low_shannon_true = 0\n",
    "for i in low_shannon_true:\n",
    "    img = x_train[i]\n",
    "    label = y_train[i]\n",
    "    img = (np.expand_dims(img,0))\n",
    "    img_pred = activation_model.predict(img)[6][0]\n",
    "    \n",
    "    dst = cv2.warpAffine(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "    dst = (np.expand_dims(dst,0))\n",
    "    dst_pred = activation_model.predict(dst)[6][0]\n",
    "    \n",
    "    if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "        count_made_false_low_shannon_true += 1\n",
    "\n",
    "\n",
    "print(\"Shannon Treshold : < 0.001\")        \n",
    "print(\"Number of inputs: \", len(low_shannon_true))        \n",
    "print(\"Error Rate: \", (count_made_false_low_shannon_true*1.0)/len(low_shannon_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Affine\n",
      "Shannon Treshold : > 0.01\n",
      "Number of inputs:  87\n",
      "Error Rates : 0.3448275862068966\n",
      "\n",
      "Shannon Treshold : > 0.025\n",
      "Number of inputs:  59\n",
      "Error Rates : 0.423728813559322\n",
      "\n",
      "Shannon Treshold : > 0.05\n",
      "Number of inputs:  43\n",
      "Error Rates : 0.4418604651162791\n",
      "\n",
      "Shannon Treshold : > 0.1\n",
      "Number of inputs:  26\n",
      "Error Rates : 0.5\n",
      "\n",
      "Shannon Treshold : > 0.2\n",
      "Number of inputs:  17\n",
      "Error Rates : 0.5294117647058824\n",
      "\n",
      "Shannon Treshold : > 0.3\n",
      "Number of inputs:  12\n",
      "Error Rates : 0.4166666666666667\n",
      "\n",
      "Shannon Treshold : > 0.4\n",
      "Number of inputs:  10\n",
      "Error Rates : 0.4\n",
      "\n",
      "Shannon Treshold : > 0.5\n",
      "Number of inputs:  8\n",
      "Error Rates : 0.5\n",
      "\n",
      "Shannon Treshold : > 0.6\n",
      "Number of inputs:  5\n",
      "Error Rates : 0.4\n",
      "\n",
      "Shannon Treshold : > 0.7\n",
      "Number of inputs:  3\n",
      "Error Rates : 0.6666666666666666\n",
      "\n",
      "Shannon Treshold : > 0.8\n",
      "Number of inputs:  2\n",
      "Error Rates : 1.0\n",
      "\n",
      "Shannon Treshold : > 0.9\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  0.9\n",
      "\n",
      "Shannon Treshold : > 1.0\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Affine\")\n",
    "thresholds = [0.01, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    high_shannon_true = []\n",
    "    for i, shannon_index in enumerate(all_shannons):\n",
    "        if shannon_index > threshold and (np.argmax(all_acts[i]) == np.argmax(y_train[i])) : \n",
    "            high_shannon_true.append(i)\n",
    "\n",
    "    print(\"Shannon Treshold : >\", threshold)\n",
    "    print(\"Number of inputs: \", len(high_shannon_true))\n",
    "\n",
    "    count_made_false_high_shannon_true = 0\n",
    "    \n",
    "    if len(high_shannon_true) > 0:\n",
    "        for i in high_shannon_true:\n",
    "            img = x_train[i]\n",
    "            label = y_train[i]\n",
    "            img = (np.expand_dims(img,0))\n",
    "            img_pred = activation_model.predict(img)[6][0]\n",
    "\n",
    "            dst = cv2.warpAffine(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "            dst = (np.expand_dims(dst,0))\n",
    "            dst_pred = activation_model.predict(dst)[6][0]\n",
    "            if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "                count_made_false_high_shannon_true += 1\n",
    "\n",
    "        print(\"Error Rates :\", (count_made_false_high_shannon_true*1.0)/len(high_shannon_true))\n",
    "        \n",
    "    else:\n",
    "        print(\"No inputs with shannon index more than \", threshold)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Perspective\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Transformation: Perspective\")\n",
    "rows,cols = (28, 28)\n",
    "pts1 = np.float32([[1,1],[25,1],[1,25],[25,25]])\n",
    "pts2 = np.float32([[0,0],[28,0],[0,28],[28,28]])\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "img = x_train[0]\n",
    "dst = cv2.warpPerspective(img,M,(cols,rows))\n",
    "plt.imshow(dst, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Perspective\n",
      "Shannon Treshold : < 0.001\n",
      "Number of inputs:  823\n",
      "Error Rate:  0.024301336573511544\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Perspective\")\n",
    "cols,rows = 28, 28\n",
    "count_made_false_low_shannon_true = 0\n",
    "for i in low_shannon_true:\n",
    "    img = x_train[i]\n",
    "    label = y_train[i]\n",
    "    img = (np.expand_dims(img,0))\n",
    "    img_pred = activation_model.predict(img)[6][0]\n",
    "    \n",
    "    dst = cv2.warpPerspective(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "    dst = (np.expand_dims(dst,0))\n",
    "    dst_pred = activation_model.predict(dst)[6][0]\n",
    "    \n",
    "    if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "        count_made_false_low_shannon_true += 1\n",
    "\n",
    "\n",
    "print(\"Shannon Treshold : < 0.001\")        \n",
    "print(\"Number of inputs: \", len(low_shannon_true))        \n",
    "print(\"Error Rate: \", (count_made_false_low_shannon_true*1.0)/len(low_shannon_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: Perspective\n",
      "Shannon Treshold : > 0.01\n",
      "Number of inputs:  87\n",
      "Error Rates : 0.1724137931034483\n",
      "\n",
      "Shannon Treshold : > 0.025\n",
      "Number of inputs:  59\n",
      "Error Rates : 0.1864406779661017\n",
      "\n",
      "Shannon Treshold : > 0.05\n",
      "Number of inputs:  43\n",
      "Error Rates : 0.18604651162790697\n",
      "\n",
      "Shannon Treshold : > 0.1\n",
      "Number of inputs:  26\n",
      "Error Rates : 0.3076923076923077\n",
      "\n",
      "Shannon Treshold : > 0.2\n",
      "Number of inputs:  17\n",
      "Error Rates : 0.4117647058823529\n",
      "\n",
      "Shannon Treshold : > 0.3\n",
      "Number of inputs:  12\n",
      "Error Rates : 0.4166666666666667\n",
      "\n",
      "Shannon Treshold : > 0.4\n",
      "Number of inputs:  10\n",
      "Error Rates : 0.4\n",
      "\n",
      "Shannon Treshold : > 0.5\n",
      "Number of inputs:  8\n",
      "Error Rates : 0.375\n",
      "\n",
      "Shannon Treshold : > 0.6\n",
      "Number of inputs:  5\n",
      "Error Rates : 0.2\n",
      "\n",
      "Shannon Treshold : > 0.7\n",
      "Number of inputs:  3\n",
      "Error Rates : 0.3333333333333333\n",
      "\n",
      "Shannon Treshold : > 0.8\n",
      "Number of inputs:  2\n",
      "Error Rates : 0.5\n",
      "\n",
      "Shannon Treshold : > 0.9\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  0.9\n",
      "\n",
      "Shannon Treshold : > 1.0\n",
      "Number of inputs:  0\n",
      "No inputs with shannon index more than  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformation: Perspective\")\n",
    "thresholds = [0.01, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    high_shannon_true = []\n",
    "    for i, shannon_index in enumerate(all_shannons):\n",
    "        if shannon_index > threshold and (np.argmax(all_acts[i]) == np.argmax(y_train[i])) : \n",
    "            high_shannon_true.append(i)\n",
    "\n",
    "    print(\"Shannon Treshold : >\", threshold)\n",
    "    print(\"Number of inputs: \", len(high_shannon_true))\n",
    "\n",
    "    count_made_false_high_shannon_true = 0\n",
    "    \n",
    "    if len(high_shannon_true) > 0:\n",
    "        for i in high_shannon_true:\n",
    "            img = x_train[i]\n",
    "            label = y_train[i]\n",
    "            img = (np.expand_dims(img,0))\n",
    "            img_pred = activation_model.predict(img)[6][0]\n",
    "\n",
    "            dst = cv2.warpPerspective(x_train[i],M,(28,28)).reshape(28,28,1)\n",
    "            dst = (np.expand_dims(dst,0))\n",
    "            dst_pred = activation_model.predict(dst)[6][0]\n",
    "            if (np.argmax(img_pred) != np.argmax(dst_pred)):\n",
    "                count_made_false_high_shannon_true += 1\n",
    "\n",
    "        print(\"Error Rates :\", (count_made_false_high_shannon_true*1.0)/len(high_shannon_true))\n",
    "        \n",
    "    else:\n",
    "        print(\"No inputs with shannon index more than \", threshold)\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
